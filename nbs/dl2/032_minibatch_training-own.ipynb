{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "##  Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=1786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data():\n",
    "    path = Config().data_path()/'mnist'\n",
    "    with gzip.open(path/'mnist.pkl.gz', 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(softmax(x), x.softmax(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### log softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (torch.exp(x) / torch.exp(x).sum(dim=-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(log_softmax(x), x.log_softmax(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### log softmax with log(a/b) rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - torch.exp(x).sum(dim=-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(log_softmax(x), x.log_softmax(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### log sum exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    a = x.max(-1, keepdim=True).values\n",
    "    return a + torch.exp(x-a).sum(dim=-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, logsumexp(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(logsumexp(x), torch.logsumexp(x, -1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### log softmax with logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]), torch.Size([2, 5]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, log_softmax(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(log_softmax(x), torch.log_softmax(x, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### cross entropy with log softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative log likelihood: sum( -x * log(p))\n",
    "\n",
    "x: one hot encoded binaries, signaling true class\n",
    "\n",
    "nll: -log(p_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_l(inp, targ):\n",
    "    return -inp[range(len(targ)),targ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(inp, targ):\n",
    "    return nll_l(log_softmax(inp), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,10)\n",
    "y = y_train[:5]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(min(y_train), max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(log_softmax(x), F.log_softmax(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll_l(x, y), F.nll_loss(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_near(crossentropy(x,y), F.cross_entropy(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "xb = x_train[:bs, :]\n",
    "yb = y_train[0:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_own(out, yb):\n",
    "    pred_cat = out.argmax(dim=-1)\n",
    "    return (pred_cat == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x_train.shape[-1], 64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3164, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(xb)\n",
    "loss = F.cross_entropy(preds, yb)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.3087, grad_fn=<NllLossBackward>), tensor(0.0901))"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x_train)\n",
    "loss = loss_func(out, y_train)\n",
    "acc = accuracy(out, y_train)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, lr):\n",
    "    for e in range(epoch):\n",
    "        for i in range(0, x_train.shape[0], bs):\n",
    "            xb, yb = x_train[i:i+bs, :], y_train[i:i+bs]\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            if i % 100 == 0: print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for l in model.layers:\n",
    "                    if hasattr(l, 'weight'):\n",
    "                        l.weight.sub_(lr*l.weight.grad)\n",
    "                        l.bias.sub_(lr*l.bias.grad)\n",
    "                        l.weight.grad.zero_()\n",
    "                        l.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3164, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0731, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6482, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5961, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4485, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3885, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4925, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4609, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5207, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3718, grad_fn=<NllLossBackward>), tensor(0.8927))"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_func(model(x_train), y_train)\n",
    "acc = accuracy_own(model(x_train), y_train)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n_in,nh)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.lin2(self.relu(self.lin1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x_train.shape[1], 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lin1): Linear(in_features=784, out_features=50, bias=True)\n",
      "(relu): ReLU()\n",
      "(lin2): Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f'({name}): {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(): Model(\n",
      "  (lin1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (lin2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "(lin1): Linear(in_features=784, out_features=50, bias=True)\n",
      "(relu): ReLU()\n",
      "(lin2): Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_modules():\n",
    "    print(f'({name}): {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lin1.weight): \t torch.Size([50, 784])\n",
      "(lin1.bias): \t torch.Size([50])\n",
      "(lin2.weight): \t torch.Size([10, 50])\n",
      "(lin2.bias): \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_parameters():\n",
    "    print(f'({name}): \\t {l.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, lr):\n",
    "    for e in range(epoch):\n",
    "        for i in range(0, x_train.shape[0], bs):\n",
    "            xb, yb = x_train[i:i+bs, :], y_train[i:i+bs]\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            if i % 100 == 0: print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.sub_(lr*p.grad)\n",
    "                    p.grad.zero_()\n",
    "#                 model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0856, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7235, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3571, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3809, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5434, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3760, grad_fn=<NllLossBackward>), tensor(0.8915))"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_func(model(x_train), y_train)\n",
    "acc = accuracy_own(model(x_train), y_train)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.lin1 = nn.Linear(n_in,nh)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(nh,n_out)\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for m in self._modules.values():\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyModule(x_train.shape[1], 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin1': Linear(in_features=784, out_features=50, bias=True),\n",
       " 'relu': ReLU(),\n",
       " 'lin2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin1': Linear(in_features=784, out_features=50, bias=True), 'relu': ReLU(), 'lin2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3127, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0662, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7052, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6953, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5799, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5585, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3843, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3502, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2655, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5319, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.shape for w in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(layers):\n",
    "            self.add_module(f'layer_{i}', l)\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0fd39adbdf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "   (layer_1): ReLU()\n",
       "   (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       " ),\n",
       " Linear(in_features=784, out_features=50, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=50, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in model.modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0fd39adbdf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   (layers): ModuleList(\n",
       "     (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "   )\n",
       " ),\n",
       " ModuleList(\n",
       "   (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=50, out_features=10, bias=True)\n",
       " ),\n",
       " Linear(in_features=784, out_features=50, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=50, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in model.modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptimizer():\n",
    "    def __init__(self, parameters, lr=0.05):\n",
    "        self.parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.parameters:\n",
    "                p.sub_(self.lr * p.grad)\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = MyOptimizer(model.parameters(), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, lr, opt):\n",
    "    for e in range(epoch):\n",
    "        for i in range(0, x_train.shape[0], bs):\n",
    "            xb, yb = x_train[i:i+bs, :], y_train[i:i+bs]\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            if i % 100 == 0: print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2874, grad_fn=<NllLossBackward>)\n",
      "tensor(5.6318, grad_fn=<NllLossBackward>)\n",
      "tensor(6.5605, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1561, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3476, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4224, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3367, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2640, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4891, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0267, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5184, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1963, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1625, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1903, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7502, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8963, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3183, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1447, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8517, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2157, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5622, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8765, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6818, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7400, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8355, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1989, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7645, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7097, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4525, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6979, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5648, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5548, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2806, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7840, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5607, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3079, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1954, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4931, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9894, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(5, 0.5, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "#     opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    opt = MyOptimizer(model.parameters(), lr=lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, i): return (self.x[i], self.y[i])\n",
    "    \n",
    "    def __len__(self): return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([50000])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([10000])\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(len(train_ds))\n",
    "print(len(valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(train_ds) == len(y_train))\n",
    "assert(len(valid_ds) == len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 784])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = train_ds[:5]\n",
    "print(xb.shape)\n",
    "print(yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, lr, opt):\n",
    "    for e in range(epoch):\n",
    "        for i in range(0, len(train_ds), bs):\n",
    "            xb, yb = train_ds[i:i+bs]\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            if i % 100 == 0: print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2989, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0851, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6298, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4115, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5644, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4997, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5437, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, model, 0.05, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0,len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_dl = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(it_dl)\n",
    "yb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 8, 7, 6])"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(it_dl)\n",
    "yb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, lr, opt):\n",
    "    for e in range(epoch):\n",
    "        for xb, yb in train_dl:\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2956, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2872, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2919, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2709, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2779, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2696, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2470, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2407, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2515, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2464, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2220, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2221, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1906, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2005, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2230, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1912, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1992, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1887, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1643, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1784, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1335, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0837, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1187, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0927, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0928, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0823, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0317, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9749, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9939, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9912, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9246, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8898, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9382, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9123, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9219, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9524, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8677, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7817, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8110, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8611, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8286, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7009, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6989, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7561, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7164, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6888, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6640, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6523, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6364, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5349, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5268, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5634, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5377, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4458, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4642, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5020, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5026, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4775, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4320, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4022, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3965, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4169, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4266, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2373, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1975, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3071, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2877, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3810, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1708, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2767, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2927, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0916, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0934, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1550, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1196, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1567, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8348, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9846, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2199, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8198, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9052, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7560, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0677, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8080, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5924, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8211, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6883, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6299, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5645, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5902, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6579, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6621, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5621, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5821, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7314, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4936, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5806, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3848, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5620, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4888, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4826, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3821, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4042, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3923, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1664, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3113, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4902, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3610, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2396, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4929, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3677, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3642, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2776, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3117, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3565, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7848, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4113, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3820, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2923, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2681, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3971, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2127, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2365, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3620, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2614, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2796, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3644, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4727, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4653, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3519, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2557, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4113, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2560, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3283, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4614, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4914, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3550, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2820, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3671, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2801, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5780, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1595, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5843, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, model, 0.05, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([3, 9, 6]), tensor([4, 0, 5]), tensor([7, 2, 8]), tensor([1])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,True)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([6, 5, 1]), tensor([0, 9, 2]), tensor([7, 4, 3]), tensor([8])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, opt):\n",
    "    for e in range(epoch):\n",
    "        for xb, yb in train_dl:\n",
    "#             print('x.shape: ', x.shape)\n",
    "#             print('y.shape: ', y.shape)\n",
    "            preds = model(xb)\n",
    "#             print('pred.shape: ', preds.shape)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3174, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3126, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2992, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2997, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2896, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2730, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2721, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2759, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2603, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2597, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2526, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2540, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2409, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2218, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2459, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2159, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2123, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1994, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1950, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1704, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1914, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1790, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1425, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1791, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1322, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1633, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1368, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1052, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1257, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0838, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0696, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1339, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0908, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0607, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0373, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0725, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0083, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0430, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0207, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9498, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9113, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9638, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9101, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8905, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9238, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9199, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8992, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8485, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8218, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8530, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8263, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8167, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7766, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6920, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7625, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7527, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7381, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7168, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7497, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6933, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7091, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6072, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5952, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6239, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5832, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6130, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4794, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5414, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5376, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5758, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3994, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4696, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5562, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4046, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3531, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4442, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3668, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3968, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3145, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4409, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3917, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3693, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3682, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4984, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4172, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1825, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1773, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2501, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1898, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2731, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1706, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2085, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1918, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2134, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1906, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1884, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2056, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0796, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1858, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0212, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0279, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9691, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8892, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8892, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8796, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7571, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7944, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7935, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6555, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5325, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5607, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5758, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4625, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2610, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4868, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4681, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4507, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5645, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4270, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4587, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4925, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4961, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3633, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5488, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3751, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2935, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4571, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5550, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4807, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3788, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3504, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4883, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6613, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3942, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3961, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4161, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4117, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3622, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3878, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2570, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4095, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4894, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4507, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5433, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4569, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6458, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4127, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5800, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4543, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6622, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2893, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3657, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4827, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4942, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3924, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2408, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8660, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3348, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3924, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3933, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3888, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1419, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, model, opt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, opt):\n",
    "    nv = len(valid_dl)\n",
    "    for e in range(epoch):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = F.cross_entropy(preds, yb)            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        #val\n",
    "        model.eval()        \n",
    "        val_acc = 0\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_dl:\n",
    "                val_preds = model(xb)\n",
    "                val_loss += F.cross_entropy(val_preds, yb)\n",
    "                val_acc += accuracy(val_preds, yb)\n",
    "            val_loss = val_loss / nv\n",
    "            val_acc = val_acc / nv\n",
    "            print(f'val_loss: {val_loss}, val_acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.09680737555027008, val_acc: 0.9727308750152588\n",
      "val_loss: 0.0958971306681633, val_acc: 0.9730294346809387\n",
      "val_loss: 0.0973888486623764, val_acc: 0.9735270738601685\n",
      "val_loss: 0.09926646202802658, val_acc: 0.9722332954406738\n",
      "val_loss: 0.0973941907286644, val_acc: 0.9728304147720337\n",
      "val_loss: 0.1012895479798317, val_acc: 0.9719347357749939\n",
      "val_loss: 0.09750808030366898, val_acc: 0.9733280539512634\n",
      "val_loss: 0.0978778749704361, val_acc: 0.9735270738601685\n",
      "val_loss: 0.09866394102573395, val_acc: 0.9733280539512634\n",
      "val_loss: 0.09939221292734146, val_acc: 0.9737260937690735\n"
     ]
    }
   ],
   "source": [
    "fit(10, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "340.997px",
    "width": "337.158px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "745.714px",
    "left": "739px",
    "top": "254.134px",
    "width": "226.057px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
